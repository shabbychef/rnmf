% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmf.r
\name{nmf}
\alias{nmf}
\title{nmf .}
\usage{
nmf(
  Y,
  L,
  R,
  W_0R = NULL,
  W_0C = NULL,
  lambda_1L = 0,
  lambda_1R = 0,
  lambda_2L = 0,
  lambda_2R = 0,
  tau = 0.5,
  annealing_rate = 0.25,
  check_optimal_step = TRUE,
  zero_tolerance = 1e-09,
  max_iterations = 1000L,
  min_xstep = 1e-09,
  verbosity = 0
)
}
\arguments{
\item{Y}{an \eqn{r \times c} matrix to be decomposed.
Should have non-negative elements, though we do not check.}

\item{L}{an \eqn{r \times d} matrix of the initial estimate of L.
Should have non-negative elements, though we do not check.}

\item{R}{an \eqn{d \times c} matrix of the initial estimate of R.
Should have non-negative elements, though we do not check.}

\item{W_0R}{the row space weighting matrix.
This should be a positive definite non-negative symmetric \eqn{r \times r} matrix.
If omitted, it defaults to the properly sized identity matrix.}

\item{W_0C}{the column space weighting matrix.
This should be a positive definite non-negative symmetric \eqn{c \times c} matrix.
If omitted, it defaults to the properly sized identity matrix.}

\item{lambda_1L}{the scalar \eqn{\ell_1} penalty for the matrix \eqn{L}.
Defaults to zero.}

\item{lambda_1R}{the scalar \eqn{\ell_1} penalty for the matrix \eqn{R}.
Defaults to zero.}

\item{lambda_2L}{the scalar \eqn{\ell_2} penalty for the matrix \eqn{L}.
Defaults to zero.}

\item{lambda_2R}{the scalar \eqn{\ell_2} penalty for the matrix \eqn{R}.
Defaults to zero.}

\item{tau}{the starting shrinkage factor applied to the step length.
Should be a value in \eqn{(0,1)}.}

\item{annealing_rate}{the rate at which we scale the shrinkage factor towards 1.
Should be a value in \eqn{[0,1)}.}

\item{check_optimal_step}{if TRUE, we attempt to take the optimal step
length in the given direction. If not, we merely take the longest feasible
step in the step direction.}

\item{zero_tolerance}{values of \eqn{x} less than this will be \sQuote{snapped} to zero.
This happens at the end of the iteration and does not affect the measurement
of convergence.}

\item{max_iterations}{the maximum number of iterations to perform.}

\item{min_xstep}{the minimum L-infinity norm of the step taken.
Once the step falls under this value, we terminate.}

\item{verbosity}{controls whether we print information to the console.}
}
\value{
a list with the elements
\describe{
\item{L}{The final estimate of L.}
\item{R}{The final estimate of R.}
\item{Lstep}{The infinity norm of the final step in L}.
\item{Rstep}{The infinity norm of the final step in R}.
\item{iterations}{The number of iterations taken.}
\item{converged}{Whether convergence was detected.}
}
}
\description{
One sentence or so that tells you some more.
}
\details{
Really detailed. \eqn{\zeta}{zeta}.

A list:
\itemize{
\item I use \eqn{n}{n} to stand for blah.
\item and so forth....
}
\describe{
\item{a}{value.}
\item{b}{factor.}
}
}
\note{
This package provides proof of concept code which is unlikely to be fast
or robust, and may not solve the optimization problem at hand. User assumes
all risk.
}
\references{
Merritt, Michael, and Zhang, Yin. "Interior-point Gradient Method for Large-Scale Totally 
Nonnegative Least Squares Problems." Journal of Optimization Theory and Applications 126, 
no 1 (2005): 191--202. \url{https://scholarship.rice.edu/bitstream/handle/1911/102020/TR04-08.pdf}
}
\author{
Steven E. Pav \email{shabbychef@gmail.com}
}
\keyword{optimization}
